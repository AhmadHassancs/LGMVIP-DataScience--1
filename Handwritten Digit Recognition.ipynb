{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from time import strftime\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN_PATH = 'MNIST/digit_xtrain.csv'\n",
    "X_TEST_PATH = 'MNIST/digit_xtest.csv'\n",
    "Y_TRAIN_PATH = 'MNIST/digit_ytrain.csv'\n",
    "Y_TEST_PATH = 'MNIST/digit_ytest.csv'\n",
    "\n",
    "NR_CLASSES = 10\n",
    "VALIDATION_SIZE = 10000\n",
    "\n",
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "CHANNELS = 1\n",
    "TOTAL_INPUTS = IMAGE_HEIGHT*IMAGE_WIDTH*CHANNELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data into an array\n",
    "y_train_all = np.loadtxt(Y_TRAIN_PATH, delimiter=',', dtype=int)\n",
    "\n",
    "y_test = np.loadtxt(Y_TEST_PATH, delimiter=',', dtype=int)\n",
    "\n",
    "x_train_all = np.loadtxt(X_TRAIN_PATH, delimiter=',', dtype=int)\n",
    "\n",
    "x_test = np.loadtxt(X_TEST_PATH, delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale the features\n",
    "x_train_all, x_test = x_train_all / 255.0 , x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Convert target values to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all = np.eye(NR_CLASSES)[y_train_all]\n",
    "\n",
    "y_test = np.eye(NR_CLASSES)[y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Create Validation dataset from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train_all[:VALIDATION_SIZE]\n",
    "\n",
    "y_val = y_train_all[:VALIDATION_SIZE]\n",
    "\n",
    "x_train = x_train_all[VALIDATION_SIZE:]\n",
    "\n",
    "y_train = y_train_all[VALIDATION_SIZE:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup TensorFlow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add/ Define tf placeholder(for features)\n",
    "X = tf.placeholder(tf.float32, shape=[None, TOTAL_INPUTS])\n",
    "\n",
    "# placeholder for labels\n",
    "Y = tf.placeholder(tf.float32, shape=[None, NR_CLASSES])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_epochs = 50\n",
    "learning_rate = 1e-3          # 0.001\n",
    "\n",
    "# 1st hidden layer(contains 512 neurons)\n",
    "n_hidden1=512\n",
    "n_hidden2=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Create Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_layer(input, weight_dim, bias_dim, name):\n",
    "    \n",
    "    with tf.name_scope(name):\n",
    "        initial_w = tf.truncated_normal(shape=weight_dim, stddev=0.1, seed=42)\n",
    "        w = tf.Variable(initial_value=initial_w)\n",
    "\n",
    "        initial_b = tf.constant(value=0.0, shape=bias_dim)\n",
    "        b = tf.Variable(initial_value=initial_b)\n",
    "\n",
    "        layer_in = tf.matmul(input, w) + b\n",
    "        \n",
    "        if name=='out':\n",
    "            layer_out = tf.nn.softmax(layer_in)\n",
    "            \n",
    "        else:\n",
    "            layer_out = tf.nn.relu(layer_in)\n",
    "            \n",
    "            \n",
    "        return layer_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) Setup Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = setup_layer(X, weight_dim=[TOTAL_INPUTS, n_hidden1], bias_dim=[n_hidden1], name='Layer_1')\n",
    "\n",
    "layer_2 = setup_layer(layer_1, weight_dim=[n_hidden1, n_hidden2], bias_dim=[n_hidden2], name='Layer_2')\n",
    "\n",
    "output = setup_layer(layer_2, weight_dim=[n_hidden2, NR_CLASSES], bias_dim=[NR_CLASSES], name='out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss, Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Loss Funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) Accuracy Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(output, axis=1), tf.argmax(Y, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Run Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Initialize all Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# feed the variables in the session\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch (Split) the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_batch = 1000\n",
    "\n",
    "num_examples = y_train.shape[0]\n",
    "nr_iterations = int(num_examples / size_of_batch)\n",
    "\n",
    "index_in_epoch = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(batch_size, data, labels):\n",
    "    \n",
    "    global num_examples\n",
    "    global index_in_epoch\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "    \n",
    "    if index_in_epoch > num_examples:\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "    \n",
    "    end = index_in_epoch\n",
    "    \n",
    "    return data[start:end], labels[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \t | Training Accuracy = [0.859]\n",
      "Epoch 1 \t | Training Accuracy = [0.867]\n",
      "Epoch 2 \t | Training Accuracy = [0.871]\n",
      "Epoch 3 \t | Training Accuracy = [0.875]\n",
      "Epoch 4 \t | Training Accuracy = [0.875]\n",
      "Epoch 5 \t | Training Accuracy = [0.965]\n",
      "Epoch 6 \t | Training Accuracy = [0.984]\n",
      "Epoch 7 \t | Training Accuracy = [0.986]\n",
      "Epoch 8 \t | Training Accuracy = [0.984]\n",
      "Epoch 9 \t | Training Accuracy = [0.986]\n",
      "Epoch 10 \t | Training Accuracy = [0.988]\n",
      "Epoch 11 \t | Training Accuracy = [0.988]\n",
      "Epoch 12 \t | Training Accuracy = [0.989]\n",
      "Epoch 13 \t | Training Accuracy = [0.989]\n",
      "Epoch 14 \t | Training Accuracy = [0.989]\n",
      "Epoch 15 \t | Training Accuracy = [0.99]\n",
      "Epoch 16 \t | Training Accuracy = [0.991]\n",
      "Epoch 17 \t | Training Accuracy = [0.991]\n",
      "Epoch 18 \t | Training Accuracy = [0.991]\n",
      "Epoch 19 \t | Training Accuracy = [0.991]\n",
      "Epoch 20 \t | Training Accuracy = [0.991]\n",
      "Epoch 21 \t | Training Accuracy = [0.991]\n",
      "Epoch 22 \t | Training Accuracy = [0.991]\n",
      "Epoch 23 \t | Training Accuracy = [0.993]\n",
      "Epoch 24 \t | Training Accuracy = [0.992]\n",
      "Epoch 25 \t | Training Accuracy = [0.992]\n",
      "Epoch 26 \t | Training Accuracy = [0.993]\n",
      "Epoch 27 \t | Training Accuracy = [0.993]\n",
      "Epoch 28 \t | Training Accuracy = [0.993]\n",
      "Epoch 29 \t | Training Accuracy = [0.993]\n",
      "Epoch 30 \t | Training Accuracy = [0.994]\n",
      "Epoch 31 \t | Training Accuracy = [0.994]\n",
      "Epoch 32 \t | Training Accuracy = [0.994]\n",
      "Epoch 33 \t | Training Accuracy = [0.994]\n",
      "Epoch 34 \t | Training Accuracy = [0.994]\n",
      "Epoch 35 \t | Training Accuracy = [0.994]\n",
      "Epoch 36 \t | Training Accuracy = [0.994]\n",
      "Epoch 37 \t | Training Accuracy = [0.994]\n",
      "Epoch 38 \t | Training Accuracy = [0.994]\n",
      "Epoch 39 \t | Training Accuracy = [0.994]\n",
      "Epoch 40 \t | Training Accuracy = [0.994]\n",
      "Epoch 41 \t | Training Accuracy = [0.994]\n",
      "Epoch 42 \t | Training Accuracy = [0.994]\n",
      "Epoch 43 \t | Training Accuracy = [0.994]\n",
      "Epoch 44 \t | Training Accuracy = [0.994]\n",
      "Epoch 45 \t | Training Accuracy = [0.994]\n",
      "Epoch 46 \t | Training Accuracy = [0.994]\n",
      "Epoch 47 \t | Training Accuracy = [0.994]\n",
      "Epoch 48 \t | Training Accuracy = [0.994]\n",
      "Epoch 49 \t | Training Accuracy = [0.994]\n",
      "Done Training!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(nr_epochs):\n",
    "    \n",
    "    # ======================= Training Dataset ======================= #\n",
    "    for i in range(nr_iterations):\n",
    "        \n",
    "        batch_x, batch_y = next_batch(batch_size=size_of_batch, data=x_train, labels=y_train)\n",
    "        \n",
    "        # Feed dictionary(to be fed into session for calculation)\n",
    "        feed_dictionary = {X:batch_x, Y:batch_y}\n",
    "        \n",
    "        sess.run(train_step, feed_dict=feed_dictionary)\n",
    "        \n",
    "  \n",
    "    batch_accuracy = sess.run(fetches=[accuracy], feed_dict=feed_dictionary)\n",
    "    \n",
    "    print(f'Epoch {epoch} \\t | Training Accuracy = {batch_accuracy}')\n",
    "\n",
    "print('Done Training!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Provide Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('MNIST/test_img.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Process the Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image into grey scale(black and white)\n",
    "bw = img.convert('L')\n",
    "\n",
    "# convert the image into an array\n",
    "img_array = np.invert(bw)\n",
    "\n",
    "# Flattening the arrray\n",
    "test_img = img_array.ravel()\n",
    "\n",
    "# feed it to tensorflow(using session(sess))\n",
    "prediction = sess.run(fetches=tf.argmax(output, axis=1),feed_dict={X:[test_img]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the test image is [2]\n"
     ]
    }
   ],
   "source": [
    "print(f'Prediction for the test image is {prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set is 97.94%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy over the test dataset\n",
    "test_accuracy = sess.run(fetches=accuracy, feed_dict={X:x_test, Y:y_test})\n",
    "\n",
    "print(f'Accuracy on test set is {test_accuracy:0.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
